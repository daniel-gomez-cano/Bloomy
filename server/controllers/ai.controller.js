import { GoogleGenerativeAI } from '@google/generative-ai'
import { verifyToken } from '../services/jwt.js'
import { User } from '../models/User.js'

const COOKIE_NAME = 'bloomy_token'

function buildPrompt({ isPremium, lat, lng, extras }) {
  const base = `
Eres un asesor agr√≠cola experto. Genera un reporte claro, estructurado y pr√°ctico en Markdown, en espa√±ol.
Genera un reporte moderno, visual, bonito y f√°cil de leer usando **solo Markdown est√°ndar**. 
NO uses arte ASCII (como cuadros hechos con "+---+"), NO uses c√≥digo para simular tablas,
NO uses delimitadores raros. Solo Markdown real.

El estilo debe ser:
- T√≠tulos claros con ## y ###.
- Tablas Markdown reales.
- Listas con bullets.
- Iconos Unicode (üå±üíßüß™‚òÄÔ∏èüêõüìå) para hacerlo visual.
- Bloques destacados usando > (quote) cuando sea √∫til.
- Diagramas simples hechos en texto pero sin bordes ASCII.
Contexto del terreno:
- Ubicaci√≥n (lat, lng): ${lat}, ${lng}
${extras?.dimensions ? `- Dimensiones aproximadas: ${extras.dimensions}` : ''}
${extras?.shape ? `- Disposici√≥n del terreno: ${extras.shape}` : ''}

Requisitos generales:
- El reporte debe ser entendible por agricultores de nivel principiante a intermedio.
- Prioriza cultivos viables para el clima general de la regi√≥n (no inventes coordenadas de ciudades).
- Incluye beneficios pr√°cticos, advertencias y recomendaciones de manejo.

Secciones obligatorias:
1. Resumen ejecutivo (3-5 bullets).
2. Lista de cultivos √≥ptimos para la zona y condiciones (3-6).
3. Gu√≠as de siembra y cuidados por cultivo (siembra, riego, fertilizaci√≥n, horas de sol, plagas comunes, cosecha).
`

  const premium = `
4. Consideraciones del historial clim√°tico de la zona (tendencias, estacionalidad, riesgos clim√°ticos).
5. An√°lisis predictivo de rendimiento por cultivo (aprox, con supuestos y rango).
6. C√°lculo de densidad ideal por planta y optimizaci√≥n de espacio/recursos.
7. Recomendaciones de fertilizaci√≥n espec√≠ficas (calendario sugerido y dosis orientativas; no hagas afirmaciones m√©dicas ni garantices rendimientos).
8. Patrones clim√°ticos relevantes y su impacto.
`

  return base + (isPremium ? premium : '') + `
Mejora visual obligatoria del reporte:
- Usa Markdown avanzado para hacerlo altamente visual.
- Divide la informaci√≥n en bloques muy claros: tablas, secciones cortas, vi√±etas.
- Usa emojis solo para resaltar visualmente (üå± riego, ‚òÄÔ∏è sol, üêõ plagas, ‚ö†Ô∏è riesgo).
- Incluye como m√≠nimo:
  - 1 tabla markdown real de comparativa de cultivos √≥ptimos.
  - 1 cronograma visual (l√≠nea de tiempo mensual) para siembra y cosecha por cultivo.
  - 1 tabla/resumen de riegos, fertilizaci√≥n y horas de sol.
  - Indicadores visuales con barras ASCII para representar niveles (por ejemplo: Riego: ‚ñà‚ñà‚ñà‚ñë‚ñë 60%).
- Mant√©n el reporte conciso y altamente escaneable.
- Evita p√°rrafos largos; usa bloques, listas y resaltados.
- No agregues mensajes introductorios ni despedidas.
  `
}

export async function generateReport(req, res) {
  try {
    const token = req.cookies?.[COOKIE_NAME]
    if (!token) return res.status(401).json({ message: 'No autenticado' })
    const payload = verifyToken(token)
    const user = await User.findById(payload.sub)
    if (!user) return res.status(401).json({ message: 'No autenticado' })

    const { lat, lng, extras } = req.body || {}
    if (typeof lat !== 'number' || typeof lng !== 'number') {
      return res.status(400).json({ message: 'Coordenadas inv√°lidas' })
    }

    const apiKey = process.env.GOOGLE_API_KEY
    if (!apiKey) return res.status(500).json({ message: 'Falta GOOGLE_API_KEY en el servidor' })

    const genAI = new GoogleGenerativeAI(apiKey)
    const modelName = process.env.GOOGLE_MODEL || 'gemini-2.5-flash'
    const model = genAI.getGenerativeModel({ model: modelName })

    const prompt = buildPrompt({ isPremium: !!user.isPremium, lat, lng, extras })
    const result = await model.generateContent(prompt)
    const text = result?.response?.text?.() || 'No se pudo generar el reporte.'
    return res.json({ report: text })
  } catch (err) {
    console.error('generateReport error', err)
    const detail = process.env.NODE_ENV === 'production' ? '' : ` (${err?.message || 'error'})`
    return res.status(500).json({ message: `No se pudo generar el reporte${detail}` })
  }
}

// ===== Chat Streaming Implementation =====
// Simple in-memory rate limiting: 8 requests per rolling 60s window per user
const chatRate = new Map() // key: userId, value: array of timestamps (ms)

function canProceed(userId) {
  const now = Date.now()
  const arr = chatRate.get(userId) || []
  // keep only last 60s
  const filtered = arr.filter(t => now - t < 60_000)
  if (filtered.length >= 8) return false
  filtered.push(now)
  chatRate.set(userId, filtered)
  return true
}

// Build chat prompt from messages (session only). Expect messages: [{role:'user'|'assistant', text:string}]
function buildChatPrompt(messages) {
  const header = `Eres Bloomy-IA, asistente agr√≠cola premium. Responde SIEMPRE en espa√±ol, con tono claro, profesional y cercano. Usa Markdown simple (p√°rrafos cortos, listas cuando aporten). No inventes datos clim√°ticos espec√≠ficos no solicitados ni hagas promesas garantizadas. Si el usuario pregunta algo fuera de agricultura, puedes responder brevemente o pedir que vuelva al contexto agr√≠cola. Evita despedidas formales, responde directo.`
  const convo = messages
    .map(m => `${m.role === 'user' ? 'Usuario' : 'Asistente'}: ${m.text.trim()}`)
    .join('\n')
  return `${header}\n\nConversaci√≥n actual:\n${convo}\n\nResponde al √∫ltimo mensaje del Usuario de forma √∫til y concisa.`
}

export async function chatStream(req, res) {
  try {
    const token = req.cookies?.[COOKIE_NAME]
    if (!token) return res.status(401).json({ message: 'No autenticado' })
    const payload = verifyToken(token)
    const user = await User.findById(payload.sub)
    if (!user) return res.status(401).json({ message: 'No autenticado' })
    if (!user.isPremium) return res.status(403).json({ message: 'Funcionalidad s√≥lo para usuarios premium' })

    if (!canProceed(user.id)) {
      return res.status(429).json({ message: 'L√≠mite de velocidad excedido (m√°x 8/min)' })
    }

    const { messages } = req.body || {}
    if (!Array.isArray(messages) || messages.length === 0) {
      return res.status(400).json({ message: 'messages requerido' })
    }

    const apiKey = process.env.GOOGLE_API_KEY
    if (!apiKey) return res.status(500).json({ message: 'Falta GOOGLE_API_KEY en el servidor' })
    const genAI = new GoogleGenerativeAI(apiKey)
    const modelName = process.env.GOOGLE_MODEL || 'gemini-2.5-flash'
    const model = genAI.getGenerativeModel({ model: modelName })
    const prompt = buildChatPrompt(messages)

    // Prepare streaming response headers
    res.setHeader('Content-Type', 'text/event-stream')
    res.setHeader('Cache-Control', 'no-cache')
    res.setHeader('Connection', 'keep-alive')
    res.flushHeaders?.()

    function sendEvent(obj) {
      res.write(`data: ${JSON.stringify(obj)}\n\n`)
    }

    try {
      // Streaming via Gemini SDK (generateContentStream). Fallback to non-stream if not available.
      if (typeof model.generateContentStream === 'function') {
        const streamResult = await model.generateContentStream({ contents: [{ role: 'user', parts: [{ text: prompt }] }] })
        for await (const item of streamResult.stream) {
          const partText = item?.text()
          if (partText) sendEvent({ token: partText })
        }
      } else {
        const result = await model.generateContent(prompt)
        const text = result?.response?.text?.() || ''
        // Emit in pseudo-chunks (split by sentence) for UX consistency
        text.split(/(?<=[.!?])\s+/).forEach(chunk => {
          if (chunk.trim()) sendEvent({ token: chunk + ' ' })
        })
      }
      sendEvent({ done: true })
      res.end()
    } catch (err) {
      console.error('chatStream inner error', err)
      sendEvent({ error: 'Error generando respuesta' })
      res.end()
    }
  } catch (err) {
    console.error('chatStream error', err)
    return res.status(500).json({ message: 'Error interno' })
  }
}
